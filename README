22.06.2014

TODO:
1. cala macierz S1 po pojedynczje modyfikacji
2. testowanie SVD + S1
3. raport

TESTY DO WYKONANIA
1. s1 z wycaiganiem pojedynczym (100% danych)
2. svd z wyciaganiem pojedynczym (5%)
3. svd z wyciaganiem pojedynczym w grupach (100%)
4. s1 + svd z wyciaganiem pojedynczym (5%)
5. test na ustalenie poziomu dla SVD

MAYBE (to mozna zapisac w rzeczach do zrobienia - trzeba takie cos zrobic w rapocie i tak :P)
1. cala macierz S1 po k modyfikacjach
2. testowanie s1 + svd (oraz svd + s1) z wyciaganiem pojedynczym w grupach
3. svd + s1 z wyciaganiem pojedynczym (moze 5%?)

21.06.2014

Co można zrobić:
1. aktualizacja SVD po wyjęciu jednego wpisu z macierzy (tak żeby dało się zrobić 100k testów w rozsądnym czasie)
2. aktualizacja Slope One + SVD po wyjęciu jednego wpisu z macierzy
3. odpalić Slope One na średnich danych (milion testów) - znowu ~8 godzin
4. bipolar
5. można coś napisać w raporcie o aktualizacji, złożoności czasowej/pamięciowej, zrobić porównanie
6. komentarze w kodzie
7. poprawianie kodu (np. żeby łatwo się testowało)

nie wiadomo w jaki sposób oni okroili te dane - to może wpływać na skuteczność poszczególnych metod
przy testowaniu Slope One na podzielonym zbiorze danych nie trzeba liczyć całej macierzy - wystarczy liczyć dla par użytkownik/film ze zbioru testowego
mogę wrzucić skrypt shellowy do dzielenia danych na dwa zbiory

